{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "import numpy as np\n",
    "import regex as regex\n",
    "import codecs\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download text files of book in public domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_files={\n",
    "#     \"Mickiewicz\": [\n",
    "#         \"https://wolnelektury.pl/media/book/txt/pan-tadeusz.txt\",\n",
    "#         \"https://wolnelektury.pl/media/book/txt/dziady-dziady-widowisko-czesc-i.txt\",\n",
    "#         \"https://wolnelektury.pl/media/book/txt/dziady-dziadow-czesci-iii-ustep-do-przyjaciol-moskali.txt\",\n",
    "#         \"https://wolnelektury.pl/media/book/txt/ballady-i-romanse-pani-twardowska.txt\",\n",
    "#         \"https://wolnelektury.pl/media/book/txt/ballady-i-romanse-powrot-taty.txt\",\n",
    "#         \"https://wolnelektury.pl/media/book/txt/ballady-i-romanse-switez.txt\",\n",
    "#         \"https://wolnelektury.pl/media/book/txt/dziady-dziady-poema-dziady-czesc-iv.txt\",\n",
    "#     ],\n",
    "    \"Sienkiewicz\": [\n",
    "        \"https://wolnelektury.pl/media/book/txt/quo-vadis.txt\",\n",
    "        \"https://wolnelektury.pl/media/book/txt/sienkiewicz-we-mgle.txt\",\n",
    "        \"https://wolnelektury.pl/media/book/txt/potop-tom-pierwszy.txt\",\n",
    "        \"https://wolnelektury.pl/media/book/txt/potop-tom-drugi.txt\",\n",
    "        \"https://wolnelektury.pl/media/book/txt/potop-tom-trzeci.txt\",\n",
    "    ],\n",
    "    \"Orzeszkowa\": [\n",
    "        \"https://wolnelektury.pl/media/book/txt/orzeszkowa-kto-winien.txt\",\n",
    "        \"https://wolnelektury.pl/media/book/txt/nad-niemnem-tom-pierwszy.txt\",\n",
    "        \"https://wolnelektury.pl/media/book/txt/nad-niemnem-tom-drugi.txt\",\n",
    "        \"https://wolnelektury.pl/media/book/txt/nad-niemnem-tom-trzeci.txt\",\n",
    "        \"https://wolnelektury.pl/media/book/txt/gloria-victis-dziwna-historia.txt\",\n",
    "        \"https://wolnelektury.pl/media/book/txt/z-pozogi.txt\",\n",
    "        \"https://wolnelektury.pl/media/book/txt/pani-dudkowa.txt\",\n",
    "        \"https://wolnelektury.pl/media/book/txt/dymy.txt\",\n",
    "        \"https://wolnelektury.pl/media/book/txt/syn-stolarza.txt\",\n",
    "        \"https://wolnelektury.pl/media/book/txt/dobra-pani.txt\",\n",
    "        \"https://wolnelektury.pl/media/book/txt/cnotliwi.txt\",\n",
    "        \"https://wolnelektury.pl/media/book/txt/kilka-slow-o-kobietach.txt\",\n",
    "        \"https://wolnelektury.pl/media/book/txt/patryotyzm-i-kosmopolityzm.txt\",\n",
    "        \"https://wolnelektury.pl/media/book/txt/julianka.txt\",\n",
    "    ],\n",
    "    \"Prus\": [\n",
    "        \"https://wolnelektury.pl/media/book/txt/lalka-tom-drugi.txt\",\n",
    "        \"https://wolnelektury.pl/media/book/txt/lalka-tom-pierwszy.txt\",\n",
    "        \"https://wolnelektury.pl/media/book/txt/antek.txt\",\n",
    "        \"https://wolnelektury.pl/media/book/txt/katarynka.txt\",\n",
    "        \"https://wolnelektury.pl/media/book/txt/prus-anielka.txt\",\n",
    "        \"https://wolnelektury.pl/media/book/txt/prus-placowka.txt\",\n",
    "        \n",
    "    ],\n",
    "    \"Reymont\": [\n",
    "        \"https://wolnelektury.pl/media/book/txt/ziemia-obiecana-tom-pierwszy.txt\",\n",
    "        \"https://wolnelektury.pl/media/book/txt/chlopi-czesc-pierwsza-jesien.txt\",\n",
    "        \"https://wolnelektury.pl/media/book/txt/reymont-chlopi-zima.txt\",\n",
    "        \"https://wolnelektury.pl/media/book/txt/chlopi-czesc-trzecia-wiosna.txt\",\n",
    "        \"https://wolnelektury.pl/media/book/txt/chlopi-czesc-czwarta-lato.txt\",\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "for author in book_files:\n",
    "    for url in book_files[author]:\n",
    "        file_path = os.path.join(\"data\",os.path.basename(url))\n",
    "        if not os.path.exists(file_path):\n",
    "            print(\"downloading {}\".format(url))\n",
    "            urlretrieve(url, file_path)\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess files. Clean nonlatin characters, remove excessive spaces and newlines. Remove wolnelektury footer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "repl_dict={    \n",
    "#     '.': '||period||',\n",
    "    ',': ' ||comma||',\n",
    "    '\"': ' ||quotation_mark||',\n",
    "    ';': ' ||semicolon||',\n",
    "    '!': ' ||exclamation_mark||',\n",
    "    '?': ' ||question_mark||',\n",
    "    '(': ' ||left_parenthesis||',\n",
    "    ')': ' ||right_parenthesis||',\n",
    "    '--': ' ||dash||',\n",
    "    '?': ' ||question_mark||',\n",
    "#     '\\n': '||return||'\n",
    "}\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    \"\"\"\n",
    "    Perform a simple multiple replace.\n",
    "    repl_dict has to be a dictionary i replace patterns.\n",
    "    The key cannot contain patterns.\n",
    "    \"\"\"\n",
    "    # build regexp\n",
    "    reg_exp = regex.compile(\"|\".join(map(regex.escape, repl_dict.keys())))\n",
    "\n",
    "    # replace :)\n",
    "    return reg_exp.sub(lambda match: repl_dict[match.group(0)], text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# output corspus file with one sentence per line\n",
    "def preprocess_file(file_path=None, file_url=None, overwrite=False):\n",
    "    if not file_path and file_url:\n",
    "        file_path = os.path.join(\"data\",os.path.basename(file_url))\n",
    "        \n",
    "    pp_file=file_path+\".pp\"\n",
    "    if not os.path.exists(pp_file) or overwrite:\n",
    "        text = open(file_path,'rb').read().lower().decode(\"utf-8\").lower()\n",
    "\n",
    "        text = regex.sub(u\"[^ \\n\\p{Latin}\\-'.?!]\", \" \",text)\n",
    "        text = regex.sub(u\"[ \\n]+\", \" \", text) # Squeeze spaces and newlines\n",
    "        text = regex.sub(r\"----- ta lektura.*\",\"\", text) # remove footer\n",
    "        text = preprocess(text)\n",
    "        with codecs.open(pp_file, 'w', 'utf-8') as fout:\n",
    "            for l in text.split('.'):\n",
    "                l=regex.sub(r\"^ \",\"\",l) # remove leading spaces\n",
    "                fout.write(l+\" ||period||\\n\")\n",
    "    return\n",
    "\n",
    "for author in book_files:\n",
    "    for url in book_files[author]:\n",
    "        preprocess_file(file_url=url)\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count number of lines in each corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sienkiewicz': 27632, 'Orzeszkowa': 14752, 'Prus': 21756, 'Reymont': 15786}\n",
      "Orzeszkowa\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14752"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_line_count(file_path=None, file_url=None):\n",
    "    \"\"\"\n",
    "    Calculate numer of lines in the file\n",
    "    \"\"\"\n",
    "    if not file_path and file_url:\n",
    "        file_path = os.path.join(\"data\",os.path.basename(file_url))\n",
    "    def blocks(files, size=65536):\n",
    "        while True:\n",
    "            b = files.read(size)\n",
    "            if not b: break\n",
    "            yield b\n",
    "\n",
    "    with codecs.open(file_path, 'r', 'utf-8') as f:\n",
    "        return sum(bl.count(\"\\n\") for bl in blocks(f))\n",
    "\n",
    "linecounts={}\n",
    "\n",
    "for author in book_files:\n",
    "    linecounts[author]=0\n",
    "    for url in book_files[author]:\n",
    "        linecounts[author]+=get_line_count(file_url=url+\".pp\")\n",
    "\n",
    "print(linecounts)\n",
    "print(min(linecounts))\n",
    "linecounts[min(linecounts)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean words per sentence:\n",
      "{'Sienkiewicz': 21.492291546033584, 'Orzeszkowa': 30.689126898047721, 'Prus': 18.751103143960286, 'Reymont': 26.537438236412012}\n",
      "Median words per sentence:\n",
      "{'Sienkiewicz': 17.0, 'Orzeszkowa': 24.0, 'Prus': 15.0, 'Reymont': 19.0}\n",
      "Max words per sentence:\n",
      "{'Sienkiewicz': 337, 'Orzeszkowa': 304, 'Prus': 276, 'Reymont': 522}\n",
      "Std dev words per sentence:\n",
      "{'Sienkiewicz': 16.443830141683854, 'Orzeszkowa': 24.966062018436322, 'Prus': 14.441170295378315, 'Reymont': 27.157258404042977}\n"
     ]
    }
   ],
   "source": [
    "def read_file_as_sentences(file_path=None, file_url=None, max_lines=2822, doc=[]):\n",
    "    if not file_path and file_url:\n",
    "        file_path = os.path.join(\"data\",os.path.basename(file_url))\n",
    "    with open(file_path,\"r\", encoding=\"utf-8\") as file:\n",
    "        for l in file:\n",
    "            doc.append(l[:-1])\n",
    "    return doc\n",
    "\n",
    "docs={}\n",
    "for author in book_files:\n",
    "    docs[author]=[]\n",
    "    for url in book_files[author]:\n",
    "        read_file_as_sentences(file_url=url+\".pp\", doc=docs[author])\n",
    "\n",
    "sentence_lengths={a: np.array([len(l.split()) for l in docs[a]]) for a in docs}\n",
    "print (\"Mean words per sentence:\")\n",
    "print ({a: np.mean(sentence_lengths[a]) for a in sentence_lengths})\n",
    "print (\"Median words per sentence:\")\n",
    "print ({a: np.median(sentence_lengths[a]) for a in sentence_lengths})\n",
    "print (\"Max words per sentence:\")\n",
    "print ({a: np.max(sentence_lengths[a]) for a in sentence_lengths})\n",
    "print (\"Std dev words per sentence:\")\n",
    "print ({a: np.std(sentence_lengths[a]) for a in sentence_lengths})\n",
    "        \n",
    "for author in docs:\n",
    "    np.random.shuffle(docs[author])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19981"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_linecount=int(np.mean([linecounts[a] for a in linecounts]))\n",
    "mean_linecount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balance all docs to the same number of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19981\n",
      "14752\n",
      "19981\n",
      "15786\n"
     ]
    }
   ],
   "source": [
    "for author in docs:\n",
    "    del(docs[author][mean_linecount:])\n",
    "for author in docs:\n",
    "    print(len(docs[author]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=10000\n",
    "\n",
    "word_counts = Counter()\n",
    "for author in docs:\n",
    "    for line in docs[author]:\n",
    "        word_counts.update(line.split())\n",
    "\n",
    "        \n",
    "vocabulary = dict(word_counts.most_common()[:vocab_size])\n",
    "\n",
    "\n",
    "# Start at 2, 0 is for padding 1 is for unknown words\n",
    "int_to_vocab = {word_id: word for word_id, word in enumerate(vocabulary,2)}\n",
    "vocab_to_int = {word: word_id for word_id, word in int_to_vocab.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build a train, verification and testing datasets, shuffle them and construct one hot encodded labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_to_ids(source_text, vocab_to_int=vocab_to_int):\n",
    "    \"\"\"\n",
    "    Convert text to proper word ids\n",
    "    :param source_text: String that contains all the source text.\n",
    "    :param vocab_to_int: Dictionary to go from the source words to an id\n",
    "    :return: A lists id_text\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1 is for Unknown words\n",
    "    id_text = [[vocab_to_int.get(w,1) for w in l.split()] for l in source_text]\n",
    "    \n",
    "    return id_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14387 3596 1998 Sienkiewicz\n",
      "10622 2655 1475 Orzeszkowa\n",
      "14387 3596 1998 Prus\n",
      "11367 2841 1578 Reymont\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = 0.1 # From all data\n",
    "valid = 0.2 # of what's left\n",
    "\n",
    "X_train=[]\n",
    "X_valid=[]\n",
    "X_test=[]\n",
    "Y_train=[]\n",
    "Y_valid=[]\n",
    "Y_test=[]\n",
    "\n",
    "#for each author chop off the same ammount of data from each author\n",
    "for author in docs:\n",
    "    sentences = len(docs[author])\n",
    "    \n",
    "    test_samples = int(sentences*test)\n",
    "    valid_samples = int((sentences-test_samples)*valid)\n",
    "    train_samples = sentences - valid_samples - test_samples\n",
    "    print (train_samples, valid_samples, test_samples, author)\n",
    "    \n",
    "    # data\n",
    "    X_train+=docs[author][:train_samples]\n",
    "    X_valid+=docs[author][train_samples:train_samples+valid_samples]\n",
    "    X_test+=docs[author][train_samples+valid_samples:]\n",
    "    \n",
    "    # labels\n",
    "    Y_train+=[author for _ in range(train_samples)]\n",
    "    Y_valid+=[author for _ in range(valid_samples)]\n",
    "    Y_test+=[author for _ in range(test_samples)]\n",
    "\n",
    "\n",
    "# Create the encoder\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "# Here the encoder finds the classes and assigns one-hot vectors \n",
    "lb.fit(list(docs.keys()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numbers\n",
    "y_train =lb.transform(Y_train)\n",
    "y_valid =lb.transform(Y_valid)\n",
    "y_test = lb.transform(Y_test)\n",
    "\n",
    "\n",
    "x_train = text_to_ids(X_train)\n",
    "x_valid = text_to_ids(X_valid)\n",
    "x_test = text_to_ids(X_test)\n",
    "\n",
    "\n",
    "# reshuffle\n",
    "def shuffle_dataset(dataset, labels):\n",
    "    (dataset) = (np.array(dataset))\n",
    "    permutation = np.random.permutation(labels.shape[0])\n",
    "    shuffled_dataset = dataset[permutation]\n",
    "    shuffled_labels = labels[permutation]\n",
    "    return shuffled_dataset, shuffled_labels\n",
    "\n",
    "x_train, y_train = shuffle_dataset(x_train, y_train)\n",
    "x_valid, y_valid = shuffle_dataset(x_valid, y_valid)\n",
    "x_test, y_test = shuffle_dataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.3.0\n",
      "Default GPU Device: /gpu:0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from distutils.version import LooseVersion\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.3'), 'Please use TensorFlow version 1.1 or newer'\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_inputs(output_dim=4):\n",
    "    \"\"\"\n",
    "    Create TF Placeholders for input, targets, learning_rate and input_sequence_length.\n",
    "    :return: Tuple (input_, targets, learning_rate, keep_prob, input_sequence_length)\n",
    "    \"\"\"\n",
    "\n",
    "    input_ = tf.placeholder(tf.int32, [None, None], name='input')\n",
    "    targets = tf.placeholder(tf.float32, [None, output_dim])\n",
    "    learning_rate = tf.placeholder(tf.float32)\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    is_training = tf.Variable(True)\n",
    "    input_sequence_length = tf.placeholder(tf.int32, [None], name=\"input_sequence_length\")\n",
    "    \n",
    "    return (input_, targets, learning_rate, keep_prob, input_sequence_length, is_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_lstm(lstm_size, num_layers, batch_size, keep_prob, inputs, vocab_size, input_sequence_length):\n",
    "    ''' Build LSTM cell.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "\n",
    "        lstm_size: Size of the hidden layers in the LSTM cells\n",
    "        num_layers: Number of LSTM layers\n",
    "        batch_size: Batch size\n",
    "        keep_prob: Scalar tensor (tf.placeholder) for the dropout keep probability\n",
    "        inputs: input tensor\n",
    "        vocab_size: input vocabulary size\n",
    "        input_sequence_length: input sequence length tensor\n",
    "        \n",
    "        Reurns\n",
    "        ------\n",
    "        touple (rnn_output, rnn_state, initial_state)\n",
    "    '''\n",
    "    \n",
    "    # embed inputs\n",
    "    embedding = tf.Variable(tf.random_uniform((vocab_size, embed_dim), -1, 1))\n",
    "    x_embed = tf.nn.embedding_lookup(embedding, inputs)\n",
    "    \n",
    "    def build_cell(rnn_size):\n",
    "        cell = tf.contrib.rnn.LSTMCell(rnn_size, initializer=tf.contrib.layers.xavier_initializer())\n",
    "        return cell\n",
    "    \n",
    "    # Construct a stacked tf.contrib.rnn.LSTMCell...\n",
    "    stacked_cell = tf.contrib.rnn.MultiRNNCell([build_cell(lstm_size) for _ in range(num_layers)])\n",
    "    # ...wrapped in a tf.contrib.rnn.DropoutWrapper\n",
    "    cell = tf.contrib.rnn.DropoutWrapper(stacked_cell, output_keep_prob=keep_prob)\n",
    "    \n",
    "    # Pass cell and embedded input to tf.nn.dynamic_rnn()\n",
    "    rnn_output, rnn_state = tf.nn.dynamic_rnn(cell, x_embed, sequence_length=input_sequence_length, dtype=tf.float32)\n",
    "    \n",
    "    # Initial state\n",
    "    initial_state = tf.identity(stacked_cell.zero_state(batch_size, tf.float32), name=\"initial_state\")\n",
    "    \n",
    "    return rnn_output, rnn_state, initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_output(cell, keep_prob, is_training, hidden_dim=1024, output_dim=3):\n",
    "    input_ = cell[:, -1]\n",
    "    dense = tf.contrib.layers.fully_connected(inputs=input_, \n",
    "                                              num_outputs=hidden_dim, \n",
    "                                              activation_fn=tf.nn.relu,\n",
    "                                              weights_initializer=tf.contrib.layers.xavier_initializer()\n",
    "                                             )\n",
    "    dense = tf.layers.batch_normalization(dense, training=is_training)\n",
    "    logits = tf.contrib.layers.fully_connected(dense, num_outputs=output_dim, activation_fn=None, \n",
    "                                            weights_initializer=tf.contrib.layers.xavier_initializer())\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name=\"1.0\"\n",
    "batch_size=128\n",
    "lstm_size=512\n",
    "num_layers=3\n",
    "embed_dim=100\n",
    "keep_probability=0.8\n",
    "\n",
    "seq_len = 31+2*27  # Sequence Mean length + 2*sigma\n",
    "output_dim=len(book_files)\n",
    "\n",
    "learning_rate=0.0006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padded_int_batch(input_batch):\n",
    "    max_len = max([len(word) for word in input_batch])\n",
    "    int_batch =  [[0] * (max_len - len(l)) + [w for w in l] for l in input_batch]\n",
    "    return int_batch\n",
    "\n",
    "\n",
    "def get_batch(input_list=x_train, output_list=y_train, batch_size=batch_size):\n",
    "    \"\"\"\n",
    "    Batch generator.\n",
    "    Input: train_set - list of words\n",
    "    Returns touple:\n",
    "    (pad_input_batch, pad_input_lengths, output_batch)\n",
    "    \"\"\"\n",
    "    for batch_i in range(0, len(input_list)//batch_size):\n",
    "        start_i = batch_i * batch_size\n",
    "\n",
    "        # Slice the right amount for the batch\n",
    "        input_batch = input_list[start_i:start_i + batch_size]\n",
    "        output_batch= output_list[start_i:start_i + batch_size]\n",
    "\n",
    "        # Pad\n",
    "        pad_input_batch = np.array(get_padded_int_batch(input_batch))\n",
    "\n",
    "        # Need the lengths for the _lengths parameters\n",
    "        pad_input_lengths = []\n",
    "        for line in pad_input_batch:\n",
    "            pad_input_lengths.append(len(line))\n",
    "        \n",
    "        yield (pad_input_batch, pad_input_lengths, output_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(epoch_count, batch_size=batch_size, lstm_size=lstm_size, num_layers=num_layers, \n",
    "          keep_probability=keep_probability, vocab_size=vocab_size, output_dim=output_dim, \n",
    "          lr=learning_rate, model_name=model_name, display_step=10):\n",
    "\n",
    "    experiment=datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    param_string = \"batch={}-lstm_size={}-num_layers={}-embed_dim={}-keep_probability={}-vocab_size={}-seq_len={}-output_dim={}-lr={}\".format(\n",
    "        batch_size, lstm_size, num_layers, embed_dim, keep_probability, vocab_size, seq_len, \n",
    "        output_dim,lr)\n",
    "    save_dir = \"writer/{}/{}/{}\".format(model_name,experiment,param_string)\n",
    "    print (save_dir)\n",
    "\n",
    "    # construct model\n",
    "    (input_, targets, learning_rate, keep_prob, input_sequence_length, is_training) = get_inputs(output_dim)\n",
    "    \n",
    "    with tf.variable_scope('LSTM'):\n",
    "        rnn_output, rnn_state, initial_state = build_lstm(lstm_size, num_layers, batch_size, keep_prob, \n",
    "                                                          input_, vocab_size, input_sequence_length)\n",
    "    with tf.variable_scope('LOGITS'):\n",
    "        logits = build_output(rnn_output, keep_prob, is_training, output_dim=output_dim)\n",
    "            \n",
    "    with tf.variable_scope('LOSS'):\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=targets, logits=logits))\n",
    "    \n",
    "    with tf.variable_scope('OPTIMIZER'):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "    # Gradient Clipping\n",
    "    gradients = optimizer.compute_gradients(loss)\n",
    "    capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients if grad is not None]\n",
    "    train_op = optimizer.apply_gradients(capped_gradients)\n",
    "\n",
    "\n",
    "    # Accuracy\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(targets, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        # Save session\n",
    "        saver = tf.train.Saver()\n",
    "        # Use Tensorboard for debuging\n",
    "        writer=tf.summary.FileWriter(save_dir)\n",
    "        writer.add_graph(sess.graph)\n",
    "        training_loss_summary=tf.summary.scalar(\"training_loss\", loss)\n",
    "        training_accuracy_summary=tf.summary.scalar(\"training_accuracy\", accuracy)\n",
    "        validation_loss_summary=tf.summary.scalar(\"validation_loss\", loss)\n",
    "        validation_accuracy_summary=tf.summary.scalar(\"validation_accuracy\", accuracy)\n",
    "                         \n",
    "        step=0\n",
    "        for epoch_i in range(1, epoch_count):\n",
    "            for batch_i, (pad_input_batch, pad_input_lengths, out_vec) in enumerate(get_batch()):\n",
    "\n",
    "                \n",
    "                if (batch_i % display_step ==0):\n",
    "                    _, _, l, a, tls, tas = sess.run([initial_state, train_op, loss, accuracy, \n",
    "                                               training_loss_summary, training_accuracy_summary], {\n",
    "                        input_: pad_input_batch,\n",
    "                        targets: out_vec,\n",
    "                        learning_rate: lr, \n",
    "                        keep_prob: keep_probability,\n",
    "                        is_training: True,\n",
    "                        input_sequence_length: pad_input_lengths,\n",
    "                    })\n",
    "\n",
    "                    # write summary for tensorboard\n",
    "                    writer.add_summary(tls, step)\n",
    "                    writer.add_summary(tas, step)\n",
    "                    \n",
    "                    (pad_input_batch, pad_input_lengths, out_vec) = next(\n",
    "                        get_batch(input_list=x_valid, output_list=y_valid))\n",
    "                    _, vl, va, vls, vas = sess.run([initial_state, loss, accuracy, \n",
    "                                                  validation_loss_summary, validation_accuracy_summary],{\n",
    "                        input_: pad_input_batch,\n",
    "                        targets: out_vec,\n",
    "                        keep_prob: 1.0,\n",
    "                        is_training: False,\n",
    "                        input_sequence_length: pad_input_lengths,\n",
    "                    })\n",
    "                    # write summary for tensorboard\n",
    "                    writer.add_summary(vls, step)\n",
    "                    writer.add_summary(vas, step)\n",
    "                    \n",
    "                    step+=1\n",
    "\n",
    "                    print(\"Epoch: {:3} | Loss: {:2.4}\\t validation loss: {:2.4} | Accuracy: {:2.4}\\t validation accuracy: {:2.4}\".\n",
    "                          format(epoch_i, l, vl, a, va))\n",
    "                else:\n",
    "                    _, _, = sess.run([initial_state, train_op], {\n",
    "                        input_: pad_input_batch,\n",
    "                        targets: out_vec,\n",
    "                        learning_rate: lr, \n",
    "                        keep_prob: keep_probability,\n",
    "                        is_training: True,\n",
    "                        input_sequence_length: pad_input_lengths,\n",
    "                    })\n",
    "\n",
    "                    \n",
    "            lr=lr*0.8 # (0.8^10 ~=0.1)\n",
    "            saver.save(sess, save_dir, global_step=epoch_i)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writer/1.0/2017-10-22 22:30:52/batch=128-lstm_size=512-num_layers=3-embed_dim=100-keep_probability=0.8-vocab_size=10000-seq_len=85-output_dim=4-lr=0.0006\n",
      "Epoch:   1 | Loss: 1.437\t validation loss: 1.38 | Accuracy: 0.2422\t validation accuracy: 0.2812\n",
      "Epoch:   1 | Loss: 1.556\t validation loss: 1.385 | Accuracy: 0.2344\t validation accuracy: 0.2344\n",
      "Epoch:   1 | Loss: 1.497\t validation loss: 1.388 | Accuracy: 0.3047\t validation accuracy: 0.2344\n",
      "Epoch:   1 | Loss: 1.428\t validation loss: 1.386 | Accuracy: 0.3828\t validation accuracy: 0.2344\n",
      "Epoch:   1 | Loss: 1.55\t validation loss: 1.38 | Accuracy: 0.2422\t validation accuracy: 0.25\n",
      "Epoch:   1 | Loss: 1.348\t validation loss: 1.376 | Accuracy: 0.4375\t validation accuracy: 0.2969\n",
      "Epoch:   1 | Loss: 1.4\t validation loss: 1.412 | Accuracy: 0.375\t validation accuracy: 0.2578\n",
      "Epoch:   1 | Loss: 1.428\t validation loss: 1.393 | Accuracy: 0.3359\t validation accuracy: 0.3047\n",
      "Epoch:   1 | Loss: 1.251\t validation loss: 1.379 | Accuracy: 0.4219\t validation accuracy: 0.2969\n",
      "Epoch:   1 | Loss: 1.389\t validation loss: 1.365 | Accuracy: 0.4219\t validation accuracy: 0.3125\n",
      "Epoch:   1 | Loss: 1.241\t validation loss: 1.4 | Accuracy: 0.4609\t validation accuracy: 0.2656\n",
      "Epoch:   1 | Loss: 1.417\t validation loss: 1.391 | Accuracy: 0.3438\t validation accuracy: 0.2969\n",
      "Epoch:   1 | Loss: 1.259\t validation loss: 1.361 | Accuracy: 0.4453\t validation accuracy: 0.3359\n",
      "Epoch:   1 | Loss: 1.272\t validation loss: 1.39 | Accuracy: 0.4297\t validation accuracy: 0.3203\n",
      "Epoch:   1 | Loss: 1.318\t validation loss: 1.352 | Accuracy: 0.4062\t validation accuracy: 0.3047\n",
      "Epoch:   1 | Loss: 1.303\t validation loss: 1.367 | Accuracy: 0.3984\t validation accuracy: 0.3516\n",
      "Epoch:   1 | Loss: 1.201\t validation loss: 1.349 | Accuracy: 0.4141\t validation accuracy: 0.3516\n",
      "Epoch:   1 | Loss: 1.293\t validation loss: 1.341 | Accuracy: 0.4297\t validation accuracy: 0.3438\n",
      "Epoch:   1 | Loss: 1.247\t validation loss: 1.359 | Accuracy: 0.4844\t validation accuracy: 0.375\n",
      "Epoch:   1 | Loss: 1.239\t validation loss: 1.348 | Accuracy: 0.4453\t validation accuracy: 0.3672\n",
      "Epoch:   1 | Loss: 1.27\t validation loss: 1.393 | Accuracy: 0.4375\t validation accuracy: 0.3203\n",
      "Epoch:   1 | Loss: 1.296\t validation loss: 1.35 | Accuracy: 0.5156\t validation accuracy: 0.2812\n",
      "Epoch:   1 | Loss: 1.06\t validation loss: 1.317 | Accuracy: 0.5234\t validation accuracy: 0.375\n",
      "Epoch:   1 | Loss: 1.234\t validation loss: 1.337 | Accuracy: 0.4453\t validation accuracy: 0.3672\n",
      "Epoch:   1 | Loss: 1.164\t validation loss: 1.303 | Accuracy: 0.5078\t validation accuracy: 0.4062\n",
      "Epoch:   1 | Loss: 0.9916\t validation loss: 1.315 | Accuracy: 0.5781\t validation accuracy: 0.4297\n",
      "Epoch:   1 | Loss: 1.19\t validation loss: 1.322 | Accuracy: 0.4297\t validation accuracy: 0.3516\n",
      "Epoch:   1 | Loss: 1.089\t validation loss: 1.327 | Accuracy: 0.5156\t validation accuracy: 0.3438\n",
      "Epoch:   1 | Loss: 1.261\t validation loss: 1.326 | Accuracy: 0.4453\t validation accuracy: 0.3516\n",
      "Epoch:   1 | Loss: 1.246\t validation loss: 1.292 | Accuracy: 0.5156\t validation accuracy: 0.3828\n",
      "Epoch:   1 | Loss: 1.149\t validation loss: 1.312 | Accuracy: 0.5391\t validation accuracy: 0.3516\n",
      "Epoch:   1 | Loss: 1.105\t validation loss: 1.32 | Accuracy: 0.5234\t validation accuracy: 0.3438\n",
      "Epoch:   1 | Loss: 1.207\t validation loss: 1.293 | Accuracy: 0.5078\t validation accuracy: 0.375\n",
      "Epoch:   1 | Loss: 1.2\t validation loss: 1.284 | Accuracy: 0.4922\t validation accuracy: 0.4062\n",
      "Epoch:   1 | Loss: 1.143\t validation loss: 1.267 | Accuracy: 0.5\t validation accuracy: 0.4375\n",
      "Epoch:   1 | Loss: 1.047\t validation loss: 1.257 | Accuracy: 0.5391\t validation accuracy: 0.4609\n",
      "Epoch:   1 | Loss: 0.9922\t validation loss: 1.244 | Accuracy: 0.5938\t validation accuracy: 0.4844\n",
      "Epoch:   1 | Loss: 1.136\t validation loss: 1.273 | Accuracy: 0.5312\t validation accuracy: 0.4297\n",
      "Epoch:   1 | Loss: 1.199\t validation loss: 1.246 | Accuracy: 0.4844\t validation accuracy: 0.4453\n",
      "Epoch:   1 | Loss: 0.9897\t validation loss: 1.287 | Accuracy: 0.5781\t validation accuracy: 0.4219\n",
      "Epoch:   2 | Loss: 1.067\t validation loss: 1.291 | Accuracy: 0.5\t validation accuracy: 0.4297\n",
      "Epoch:   2 | Loss: 0.961\t validation loss: 1.269 | Accuracy: 0.6172\t validation accuracy: 0.4219\n",
      "Epoch:   2 | Loss: 1.097\t validation loss: 1.239 | Accuracy: 0.5156\t validation accuracy: 0.4531\n",
      "Epoch:   2 | Loss: 1.023\t validation loss: 1.235 | Accuracy: 0.5312\t validation accuracy: 0.4375\n",
      "Epoch:   2 | Loss: 1.001\t validation loss: 1.286 | Accuracy: 0.5859\t validation accuracy: 0.4062\n",
      "Epoch:   2 | Loss: 0.9636\t validation loss: 1.269 | Accuracy: 0.5938\t validation accuracy: 0.4297\n",
      "Epoch:   2 | Loss: 0.9583\t validation loss: 1.221 | Accuracy: 0.6094\t validation accuracy: 0.4219\n",
      "Epoch:   2 | Loss: 1.018\t validation loss: 1.201 | Accuracy: 0.5703\t validation accuracy: 0.5078\n",
      "Epoch:   2 | Loss: 0.8174\t validation loss: 1.181 | Accuracy: 0.6797\t validation accuracy: 0.4609\n",
      "Epoch:   2 | Loss: 1.025\t validation loss: 1.247 | Accuracy: 0.5859\t validation accuracy: 0.4609\n",
      "Epoch:   2 | Loss: 0.88\t validation loss: 1.205 | Accuracy: 0.6484\t validation accuracy: 0.4688\n",
      "Epoch:   2 | Loss: 0.8102\t validation loss: 1.184 | Accuracy: 0.6641\t validation accuracy: 0.4844\n",
      "Epoch:   2 | Loss: 0.8377\t validation loss: 1.234 | Accuracy: 0.6328\t validation accuracy: 0.4531\n",
      "Epoch:   2 | Loss: 0.9152\t validation loss: 1.19 | Accuracy: 0.6328\t validation accuracy: 0.4922\n",
      "Epoch:   2 | Loss: 0.811\t validation loss: 1.183 | Accuracy: 0.6094\t validation accuracy: 0.4375\n",
      "Epoch:   2 | Loss: 0.9158\t validation loss: 1.208 | Accuracy: 0.6562\t validation accuracy: 0.4844\n",
      "Epoch:   2 | Loss: 0.8268\t validation loss: 1.179 | Accuracy: 0.6641\t validation accuracy: 0.4766\n",
      "Epoch:   2 | Loss: 0.9819\t validation loss: 1.209 | Accuracy: 0.5625\t validation accuracy: 0.4766\n",
      "Epoch:   2 | Loss: 0.813\t validation loss: 1.17 | Accuracy: 0.6172\t validation accuracy: 0.4766\n",
      "Epoch:   2 | Loss: 0.6877\t validation loss: 1.182 | Accuracy: 0.6953\t validation accuracy: 0.4766\n",
      "Epoch:   2 | Loss: 0.8776\t validation loss: 1.183 | Accuracy: 0.6797\t validation accuracy: 0.4844\n",
      "Epoch:   2 | Loss: 0.8669\t validation loss: 1.148 | Accuracy: 0.6406\t validation accuracy: 0.4922\n",
      "Epoch:   2 | Loss: 0.7485\t validation loss: 1.16 | Accuracy: 0.7109\t validation accuracy: 0.4766\n",
      "Epoch:   2 | Loss: 0.7768\t validation loss: 1.17 | Accuracy: 0.6797\t validation accuracy: 0.4688\n",
      "Epoch:   2 | Loss: 0.8487\t validation loss: 1.187 | Accuracy: 0.6641\t validation accuracy: 0.4609\n",
      "Epoch:   2 | Loss: 0.6212\t validation loss: 1.139 | Accuracy: 0.7266\t validation accuracy: 0.5078\n",
      "Epoch:   2 | Loss: 0.9681\t validation loss: 1.136 | Accuracy: 0.6172\t validation accuracy: 0.4531\n",
      "Epoch:   2 | Loss: 0.7066\t validation loss: 1.161 | Accuracy: 0.6641\t validation accuracy: 0.4766\n",
      "Epoch:   2 | Loss: 0.9289\t validation loss: 1.227 | Accuracy: 0.6172\t validation accuracy: 0.4688\n",
      "Epoch:   2 | Loss: 0.9483\t validation loss: 1.129 | Accuracy: 0.6406\t validation accuracy: 0.5078\n",
      "Epoch:   2 | Loss: 0.6791\t validation loss: 1.157 | Accuracy: 0.7812\t validation accuracy: 0.4688\n",
      "Epoch:   2 | Loss: 0.6881\t validation loss: 1.11 | Accuracy: 0.7031\t validation accuracy: 0.4922\n",
      "Epoch:   2 | Loss: 0.8785\t validation loss: 1.148 | Accuracy: 0.6562\t validation accuracy: 0.4531\n",
      "Epoch:   2 | Loss: 0.7858\t validation loss: 1.192 | Accuracy: 0.6719\t validation accuracy: 0.4297\n",
      "Epoch:   2 | Loss: 0.8615\t validation loss: 1.147 | Accuracy: 0.6094\t validation accuracy: 0.5156\n",
      "Epoch:   2 | Loss: 0.7707\t validation loss: 1.183 | Accuracy: 0.6719\t validation accuracy: 0.4375\n",
      "Epoch:   2 | Loss: 0.7087\t validation loss: 1.113 | Accuracy: 0.6797\t validation accuracy: 0.5234\n",
      "Epoch:   2 | Loss: 0.9481\t validation loss: 1.141 | Accuracy: 0.6094\t validation accuracy: 0.5\n",
      "Epoch:   2 | Loss: 0.9256\t validation loss: 1.117 | Accuracy: 0.6328\t validation accuracy: 0.4844\n",
      "Epoch:   2 | Loss: 0.7355\t validation loss: 1.16 | Accuracy: 0.6875\t validation accuracy: 0.5\n",
      "Epoch:   3 | Loss: 0.7076\t validation loss: 1.146 | Accuracy: 0.7188\t validation accuracy: 0.4922\n",
      "Epoch:   3 | Loss: 0.7783\t validation loss: 1.171 | Accuracy: 0.6562\t validation accuracy: 0.5078\n",
      "Epoch:   3 | Loss: 0.7951\t validation loss: 1.138 | Accuracy: 0.6875\t validation accuracy: 0.4922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   3 | Loss: 0.7614\t validation loss: 1.116 | Accuracy: 0.6953\t validation accuracy: 0.5078\n",
      "Epoch:   3 | Loss: 0.8113\t validation loss: 1.164 | Accuracy: 0.6562\t validation accuracy: 0.5078\n",
      "Epoch:   3 | Loss: 0.6388\t validation loss: 1.106 | Accuracy: 0.7188\t validation accuracy: 0.5156\n",
      "Epoch:   3 | Loss: 0.7646\t validation loss: 1.096 | Accuracy: 0.6875\t validation accuracy: 0.5\n",
      "Epoch:   3 | Loss: 0.7236\t validation loss: 1.149 | Accuracy: 0.7031\t validation accuracy: 0.5234\n",
      "Epoch:   3 | Loss: 0.5854\t validation loss: 1.046 | Accuracy: 0.8047\t validation accuracy: 0.5547\n",
      "Epoch:   3 | Loss: 0.734\t validation loss: 1.059 | Accuracy: 0.6953\t validation accuracy: 0.5469\n",
      "Epoch:   3 | Loss: 0.6907\t validation loss: 1.108 | Accuracy: 0.7188\t validation accuracy: 0.4922\n",
      "Epoch:   3 | Loss: 0.6623\t validation loss: 1.077 | Accuracy: 0.7578\t validation accuracy: 0.5234\n",
      "Epoch:   3 | Loss: 0.6489\t validation loss: 1.075 | Accuracy: 0.7578\t validation accuracy: 0.4844\n",
      "Epoch:   3 | Loss: 0.7522\t validation loss: 1.072 | Accuracy: 0.7344\t validation accuracy: 0.5234\n",
      "Epoch:   3 | Loss: 0.6052\t validation loss: 1.085 | Accuracy: 0.7578\t validation accuracy: 0.5078\n",
      "Epoch:   3 | Loss: 0.7369\t validation loss: 1.068 | Accuracy: 0.7266\t validation accuracy: 0.5\n",
      "Epoch:   3 | Loss: 0.6119\t validation loss: 1.103 | Accuracy: 0.7578\t validation accuracy: 0.4922\n",
      "Epoch:   3 | Loss: 0.7958\t validation loss: 1.092 | Accuracy: 0.6875\t validation accuracy: 0.4766\n",
      "Epoch:   3 | Loss: 0.6045\t validation loss: 1.095 | Accuracy: 0.7422\t validation accuracy: 0.5391\n",
      "Epoch:   3 | Loss: 0.5021\t validation loss: 1.037 | Accuracy: 0.7969\t validation accuracy: 0.5703\n",
      "Epoch:   3 | Loss: 0.6793\t validation loss: 1.063 | Accuracy: 0.7656\t validation accuracy: 0.5391\n",
      "Epoch:   3 | Loss: 0.6418\t validation loss: 1.082 | Accuracy: 0.7422\t validation accuracy: 0.5312\n",
      "Epoch:   3 | Loss: 0.533\t validation loss: 1.037 | Accuracy: 0.7734\t validation accuracy: 0.5391\n",
      "Epoch:   3 | Loss: 0.5595\t validation loss: 1.064 | Accuracy: 0.7656\t validation accuracy: 0.5\n",
      "Epoch:   3 | Loss: 0.6913\t validation loss: 1.099 | Accuracy: 0.6953\t validation accuracy: 0.5312\n",
      "Epoch:   3 | Loss: 0.5085\t validation loss: 1.062 | Accuracy: 0.8281\t validation accuracy: 0.5078\n",
      "Epoch:   3 | Loss: 0.759\t validation loss: 1.059 | Accuracy: 0.6562\t validation accuracy: 0.4766\n",
      "Epoch:   3 | Loss: 0.5889\t validation loss: 1.058 | Accuracy: 0.7188\t validation accuracy: 0.5469\n",
      "Epoch:   3 | Loss: 0.7119\t validation loss: 1.108 | Accuracy: 0.7109\t validation accuracy: 0.5234\n",
      "Epoch:   3 | Loss: 0.7446\t validation loss: 1.086 | Accuracy: 0.6953\t validation accuracy: 0.5312\n",
      "Epoch:   3 | Loss: 0.5281\t validation loss: 1.058 | Accuracy: 0.7891\t validation accuracy: 0.5312\n",
      "Epoch:   3 | Loss: 0.5103\t validation loss: 1.023 | Accuracy: 0.7891\t validation accuracy: 0.5859\n",
      "Epoch:   3 | Loss: 0.6907\t validation loss: 1.082 | Accuracy: 0.7578\t validation accuracy: 0.4922\n",
      "Epoch:   3 | Loss: 0.5919\t validation loss: 1.077 | Accuracy: 0.7891\t validation accuracy: 0.5078\n",
      "Epoch:   3 | Loss: 0.7314\t validation loss: 1.077 | Accuracy: 0.6641\t validation accuracy: 0.5312\n",
      "Epoch:   3 | Loss: 0.6229\t validation loss: 1.088 | Accuracy: 0.7812\t validation accuracy: 0.5234\n",
      "Epoch:   3 | Loss: 0.5318\t validation loss: 1.048 | Accuracy: 0.7656\t validation accuracy: 0.5469\n",
      "Epoch:   3 | Loss: 0.8432\t validation loss: 1.12 | Accuracy: 0.6641\t validation accuracy: 0.5312\n",
      "Epoch:   3 | Loss: 0.6887\t validation loss: 1.026 | Accuracy: 0.6875\t validation accuracy: 0.5156\n",
      "Epoch:   3 | Loss: 0.635\t validation loss: 1.078 | Accuracy: 0.7344\t validation accuracy: 0.5234\n",
      "Epoch:   4 | Loss: 0.6066\t validation loss: 1.072 | Accuracy: 0.7891\t validation accuracy: 0.5312\n",
      "Epoch:   4 | Loss: 0.6223\t validation loss: 1.074 | Accuracy: 0.7578\t validation accuracy: 0.5703\n",
      "Epoch:   4 | Loss: 0.6387\t validation loss: 1.06 | Accuracy: 0.7422\t validation accuracy: 0.5391\n",
      "Epoch:   4 | Loss: 0.6603\t validation loss: 1.062 | Accuracy: 0.7109\t validation accuracy: 0.5469\n",
      "Epoch:   4 | Loss: 0.6771\t validation loss: 1.145 | Accuracy: 0.7109\t validation accuracy: 0.5078\n",
      "Epoch:   4 | Loss: 0.4822\t validation loss: 1.065 | Accuracy: 0.7891\t validation accuracy: 0.5469\n",
      "Epoch:   4 | Loss: 0.6458\t validation loss: 1.063 | Accuracy: 0.7188\t validation accuracy: 0.5312\n",
      "Epoch:   4 | Loss: 0.5907\t validation loss: 1.1 | Accuracy: 0.7812\t validation accuracy: 0.4844\n",
      "Epoch:   4 | Loss: 0.4436\t validation loss: 1.034 | Accuracy: 0.8594\t validation accuracy: 0.5703\n",
      "Epoch:   4 | Loss: 0.5818\t validation loss: 1.011 | Accuracy: 0.7656\t validation accuracy: 0.5703\n",
      "Epoch:   4 | Loss: 0.576\t validation loss: 1.023 | Accuracy: 0.75\t validation accuracy: 0.5625\n",
      "Epoch:   4 | Loss: 0.5723\t validation loss: 1.005 | Accuracy: 0.8203\t validation accuracy: 0.5703\n",
      "Epoch:   4 | Loss: 0.565\t validation loss: 1.005 | Accuracy: 0.7969\t validation accuracy: 0.5625\n",
      "Epoch:   4 | Loss: 0.66\t validation loss: 1.005 | Accuracy: 0.7734\t validation accuracy: 0.5625\n",
      "Epoch:   4 | Loss: 0.5254\t validation loss: 1.022 | Accuracy: 0.7891\t validation accuracy: 0.5312\n",
      "Epoch:   4 | Loss: 0.6559\t validation loss: 1.009 | Accuracy: 0.7656\t validation accuracy: 0.5547\n",
      "Epoch:   4 | Loss: 0.5269\t validation loss: 1.015 | Accuracy: 0.7969\t validation accuracy: 0.5391\n",
      "Epoch:   4 | Loss: 0.6547\t validation loss: 1.052 | Accuracy: 0.75\t validation accuracy: 0.4922\n",
      "Epoch:   4 | Loss: 0.4777\t validation loss: 1.035 | Accuracy: 0.7969\t validation accuracy: 0.5156\n",
      "Epoch:   4 | Loss: 0.3845\t validation loss: 0.9778 | Accuracy: 0.8203\t validation accuracy: 0.6016\n",
      "Epoch:   4 | Loss: 0.5598\t validation loss: 0.9618 | Accuracy: 0.8203\t validation accuracy: 0.5938\n",
      "Epoch:   4 | Loss: 0.5545\t validation loss: 0.9882 | Accuracy: 0.7578\t validation accuracy: 0.5625\n",
      "Epoch:   4 | Loss: 0.4717\t validation loss: 0.9783 | Accuracy: 0.8125\t validation accuracy: 0.5781\n",
      "Epoch:   4 | Loss: 0.4611\t validation loss: 1.001 | Accuracy: 0.7969\t validation accuracy: 0.5469\n",
      "Epoch:   4 | Loss: 0.5822\t validation loss: 1.01 | Accuracy: 0.75\t validation accuracy: 0.5391\n",
      "Epoch:   4 | Loss: 0.4717\t validation loss: 0.9557 | Accuracy: 0.8359\t validation accuracy: 0.5781\n",
      "Epoch:   4 | Loss: 0.6746\t validation loss: 1.007 | Accuracy: 0.7188\t validation accuracy: 0.4922\n",
      "Epoch:   4 | Loss: 0.49\t validation loss: 0.979 | Accuracy: 0.7734\t validation accuracy: 0.5391\n",
      "Epoch:   4 | Loss: 0.6308\t validation loss: 1.006 | Accuracy: 0.7422\t validation accuracy: 0.5547\n",
      "Epoch:   4 | Loss: 0.6616\t validation loss: 1.036 | Accuracy: 0.7266\t validation accuracy: 0.5781\n",
      "Epoch:   4 | Loss: 0.4324\t validation loss: 0.9908 | Accuracy: 0.8359\t validation accuracy: 0.5703\n",
      "Epoch:   4 | Loss: 0.4889\t validation loss: 0.9567 | Accuracy: 0.7734\t validation accuracy: 0.5938\n",
      "Epoch:   4 | Loss: 0.5396\t validation loss: 1.01 | Accuracy: 0.8047\t validation accuracy: 0.5703\n",
      "Epoch:   4 | Loss: 0.5352\t validation loss: 1.029 | Accuracy: 0.7969\t validation accuracy: 0.5312\n",
      "Epoch:   4 | Loss: 0.6259\t validation loss: 0.9961 | Accuracy: 0.7109\t validation accuracy: 0.5703\n",
      "Epoch:   4 | Loss: 0.548\t validation loss: 1.001 | Accuracy: 0.7969\t validation accuracy: 0.5469\n",
      "Epoch:   4 | Loss: 0.4352\t validation loss: 0.9635 | Accuracy: 0.8047\t validation accuracy: 0.6016\n",
      "Epoch:   4 | Loss: 0.7357\t validation loss: 0.9775 | Accuracy: 0.6875\t validation accuracy: 0.6172\n",
      "Epoch:   4 | Loss: 0.5886\t validation loss: 0.9593 | Accuracy: 0.7109\t validation accuracy: 0.5703\n",
      "Epoch:   4 | Loss: 0.5389\t validation loss: 0.9832 | Accuracy: 0.75\t validation accuracy: 0.6094\n",
      "Epoch:   5 | Loss: 0.5513\t validation loss: 0.9998 | Accuracy: 0.7812\t validation accuracy: 0.6016\n",
      "Epoch:   5 | Loss: 0.53\t validation loss: 0.9873 | Accuracy: 0.8438\t validation accuracy: 0.5938\n",
      "Epoch:   5 | Loss: 0.5485\t validation loss: 0.9633 | Accuracy: 0.7812\t validation accuracy: 0.5859\n",
      "Epoch:   5 | Loss: 0.5707\t validation loss: 0.9681 | Accuracy: 0.7891\t validation accuracy: 0.5781\n",
      "Epoch:   5 | Loss: 0.5991\t validation loss: 1.039 | Accuracy: 0.7344\t validation accuracy: 0.5938\n",
      "Epoch:   5 | Loss: 0.3996\t validation loss: 0.977 | Accuracy: 0.8359\t validation accuracy: 0.6094\n",
      "Epoch:   5 | Loss: 0.5656\t validation loss: 0.9552 | Accuracy: 0.7578\t validation accuracy: 0.6094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   5 | Loss: 0.5046\t validation loss: 1.039 | Accuracy: 0.7812\t validation accuracy: 0.5234\n",
      "Epoch:   5 | Loss: 0.3886\t validation loss: 1.02 | Accuracy: 0.8516\t validation accuracy: 0.5781\n",
      "Epoch:   5 | Loss: 0.493\t validation loss: 0.9761 | Accuracy: 0.7734\t validation accuracy: 0.6094\n",
      "Epoch:   5 | Loss: 0.5312\t validation loss: 0.9906 | Accuracy: 0.7656\t validation accuracy: 0.5781\n",
      "Epoch:   5 | Loss: 0.5475\t validation loss: 0.964 | Accuracy: 0.8047\t validation accuracy: 0.6094\n",
      "Epoch:   5 | Loss: 0.5194\t validation loss: 0.9549 | Accuracy: 0.8125\t validation accuracy: 0.6094\n",
      "Epoch:   5 | Loss: 0.5886\t validation loss: 0.929 | Accuracy: 0.8125\t validation accuracy: 0.6328\n",
      "Epoch:   5 | Loss: 0.4815\t validation loss: 0.9356 | Accuracy: 0.8203\t validation accuracy: 0.5938\n",
      "Epoch:   5 | Loss: 0.5507\t validation loss: 0.9375 | Accuracy: 0.8047\t validation accuracy: 0.5625\n",
      "Epoch:   5 | Loss: 0.4368\t validation loss: 0.9395 | Accuracy: 0.8281\t validation accuracy: 0.6016\n",
      "Epoch:   5 | Loss: 0.6108\t validation loss: 0.9674 | Accuracy: 0.7656\t validation accuracy: 0.5547\n",
      "Epoch:   5 | Loss: 0.4049\t validation loss: 0.9597 | Accuracy: 0.8438\t validation accuracy: 0.5703\n",
      "Epoch:   5 | Loss: 0.3291\t validation loss: 0.9294 | Accuracy: 0.8672\t validation accuracy: 0.5938\n",
      "Epoch:   5 | Loss: 0.5015\t validation loss: 0.9217 | Accuracy: 0.8281\t validation accuracy: 0.6172\n",
      "Epoch:   5 | Loss: 0.4865\t validation loss: 0.9301 | Accuracy: 0.8125\t validation accuracy: 0.5938\n",
      "Epoch:   5 | Loss: 0.4309\t validation loss: 0.9253 | Accuracy: 0.8125\t validation accuracy: 0.5859\n",
      "Epoch:   5 | Loss: 0.4191\t validation loss: 0.9292 | Accuracy: 0.8281\t validation accuracy: 0.6094\n",
      "Epoch:   5 | Loss: 0.5202\t validation loss: 0.9263 | Accuracy: 0.75\t validation accuracy: 0.5859\n",
      "Epoch:   5 | Loss: 0.4173\t validation loss: 0.9038 | Accuracy: 0.8594\t validation accuracy: 0.6016\n",
      "Epoch:   5 | Loss: 0.594\t validation loss: 0.9345 | Accuracy: 0.7578\t validation accuracy: 0.5625\n",
      "Epoch:   5 | Loss: 0.3998\t validation loss: 0.9153 | Accuracy: 0.8359\t validation accuracy: 0.5625\n",
      "Epoch:   5 | Loss: 0.5882\t validation loss: 0.9412 | Accuracy: 0.7578\t validation accuracy: 0.5703\n",
      "Epoch:   5 | Loss: 0.633\t validation loss: 0.9741 | Accuracy: 0.75\t validation accuracy: 0.5781\n",
      "Epoch:   5 | Loss: 0.384\t validation loss: 0.927 | Accuracy: 0.8828\t validation accuracy: 0.5859\n",
      "Epoch:   5 | Loss: 0.4439\t validation loss: 0.9075 | Accuracy: 0.8438\t validation accuracy: 0.5938\n",
      "Epoch:   5 | Loss: 0.4674\t validation loss: 0.9068 | Accuracy: 0.7969\t validation accuracy: 0.6016\n",
      "Epoch:   5 | Loss: 0.4477\t validation loss: 0.9694 | Accuracy: 0.8516\t validation accuracy: 0.5625\n",
      "Epoch:   5 | Loss: 0.556\t validation loss: 0.9425 | Accuracy: 0.7734\t validation accuracy: 0.5938\n",
      "Epoch:   5 | Loss: 0.4972\t validation loss: 0.9459 | Accuracy: 0.8203\t validation accuracy: 0.5781\n",
      "Epoch:   5 | Loss: 0.3827\t validation loss: 0.9116 | Accuracy: 0.8438\t validation accuracy: 0.6328\n",
      "Epoch:   5 | Loss: 0.6858\t validation loss: 0.9203 | Accuracy: 0.7188\t validation accuracy: 0.6172\n",
      "Epoch:   5 | Loss: 0.5442\t validation loss: 0.9038 | Accuracy: 0.7734\t validation accuracy: 0.625\n",
      "Epoch:   5 | Loss: 0.4852\t validation loss: 0.9293 | Accuracy: 0.7734\t validation accuracy: 0.6172\n",
      "Epoch:   6 | Loss: 0.5014\t validation loss: 0.9599 | Accuracy: 0.7969\t validation accuracy: 0.6172\n",
      "Epoch:   6 | Loss: 0.517\t validation loss: 0.9501 | Accuracy: 0.8359\t validation accuracy: 0.6016\n",
      "Epoch:   6 | Loss: 0.4587\t validation loss: 0.9282 | Accuracy: 0.8281\t validation accuracy: 0.6016\n",
      "Epoch:   6 | Loss: 0.5152\t validation loss: 0.9286 | Accuracy: 0.8047\t validation accuracy: 0.5859\n",
      "Epoch:   6 | Loss: 0.5327\t validation loss: 0.9839 | Accuracy: 0.7578\t validation accuracy: 0.6016\n",
      "Epoch:   6 | Loss: 0.3414\t validation loss: 0.9433 | Accuracy: 0.8516\t validation accuracy: 0.6172\n",
      "Epoch:   6 | Loss: 0.493\t validation loss: 0.9195 | Accuracy: 0.8438\t validation accuracy: 0.6016\n",
      "Epoch:   6 | Loss: 0.4618\t validation loss: 0.9677 | Accuracy: 0.8047\t validation accuracy: 0.5781\n",
      "Epoch:   6 | Loss: 0.3317\t validation loss: 0.9684 | Accuracy: 0.8984\t validation accuracy: 0.5859\n",
      "Epoch:   6 | Loss: 0.4192\t validation loss: 0.9281 | Accuracy: 0.8047\t validation accuracy: 0.6328\n",
      "Epoch:   6 | Loss: 0.4691\t validation loss: 0.9326 | Accuracy: 0.7969\t validation accuracy: 0.5859\n",
      "Epoch:   6 | Loss: 0.5092\t validation loss: 0.9163 | Accuracy: 0.8125\t validation accuracy: 0.625\n",
      "Epoch:   6 | Loss: 0.4717\t validation loss: 0.911 | Accuracy: 0.8203\t validation accuracy: 0.625\n",
      "Epoch:   6 | Loss: 0.5541\t validation loss: 0.8939 | Accuracy: 0.8281\t validation accuracy: 0.625\n",
      "Epoch:   6 | Loss: 0.4225\t validation loss: 0.8933 | Accuracy: 0.8359\t validation accuracy: 0.6406\n",
      "Epoch:   6 | Loss: 0.5171\t validation loss: 0.901 | Accuracy: 0.8438\t validation accuracy: 0.6094\n",
      "Epoch:   6 | Loss: 0.386\t validation loss: 0.9005 | Accuracy: 0.8359\t validation accuracy: 0.6172\n",
      "Epoch:   6 | Loss: 0.5557\t validation loss: 0.9155 | Accuracy: 0.8047\t validation accuracy: 0.5781\n",
      "Epoch:   6 | Loss: 0.3765\t validation loss: 0.9305 | Accuracy: 0.8594\t validation accuracy: 0.5938\n",
      "Epoch:   6 | Loss: 0.2837\t validation loss: 0.8993 | Accuracy: 0.8906\t validation accuracy: 0.6172\n",
      "Epoch:   6 | Loss: 0.4524\t validation loss: 0.9016 | Accuracy: 0.8359\t validation accuracy: 0.6094\n",
      "Epoch:   6 | Loss: 0.4324\t validation loss: 0.9087 | Accuracy: 0.7969\t validation accuracy: 0.5938\n",
      "Epoch:   6 | Loss: 0.3971\t validation loss: 0.9004 | Accuracy: 0.8281\t validation accuracy: 0.6016\n",
      "Epoch:   6 | Loss: 0.3689\t validation loss: 0.906 | Accuracy: 0.8281\t validation accuracy: 0.6094\n",
      "Epoch:   6 | Loss: 0.4568\t validation loss: 0.8905 | Accuracy: 0.8047\t validation accuracy: 0.6016\n",
      "Epoch:   6 | Loss: 0.3818\t validation loss: 0.8693 | Accuracy: 0.8594\t validation accuracy: 0.625\n",
      "Epoch:   6 | Loss: 0.5537\t validation loss: 0.8787 | Accuracy: 0.7734\t validation accuracy: 0.6172\n",
      "Epoch:   6 | Loss: 0.2995\t validation loss: 0.8483 | Accuracy: 0.875\t validation accuracy: 0.6094\n",
      "Epoch:   6 | Loss: 0.4983\t validation loss: 0.8654 | Accuracy: 0.8203\t validation accuracy: 0.6094\n",
      "Epoch:   6 | Loss: 0.5657\t validation loss: 0.9012 | Accuracy: 0.7578\t validation accuracy: 0.6094\n",
      "Epoch:   6 | Loss: 0.3736\t validation loss: 0.8907 | Accuracy: 0.875\t validation accuracy: 0.6094\n",
      "Epoch:   6 | Loss: 0.3964\t validation loss: 0.8791 | Accuracy: 0.8516\t validation accuracy: 0.625\n",
      "Epoch:   6 | Loss: 0.4246\t validation loss: 0.847 | Accuracy: 0.8203\t validation accuracy: 0.6328\n",
      "Epoch:   6 | Loss: 0.3564\t validation loss: 0.9018 | Accuracy: 0.8984\t validation accuracy: 0.6016\n",
      "Epoch:   6 | Loss: 0.5085\t validation loss: 0.861 | Accuracy: 0.7969\t validation accuracy: 0.6172\n",
      "Epoch:   6 | Loss: 0.4182\t validation loss: 0.8736 | Accuracy: 0.8594\t validation accuracy: 0.6172\n",
      "Epoch:   6 | Loss: 0.3611\t validation loss: 0.8631 | Accuracy: 0.8281\t validation accuracy: 0.6484\n",
      "Epoch:   6 | Loss: 0.6419\t validation loss: 0.8628 | Accuracy: 0.7422\t validation accuracy: 0.6406\n",
      "Epoch:   6 | Loss: 0.4568\t validation loss: 0.8652 | Accuracy: 0.8125\t validation accuracy: 0.6484\n",
      "Epoch:   6 | Loss: 0.4349\t validation loss: 0.861 | Accuracy: 0.8047\t validation accuracy: 0.6406\n",
      "Epoch:   7 | Loss: 0.4381\t validation loss: 0.8771 | Accuracy: 0.8281\t validation accuracy: 0.6172\n",
      "Epoch:   7 | Loss: 0.4676\t validation loss: 0.8914 | Accuracy: 0.8359\t validation accuracy: 0.6172\n",
      "Epoch:   7 | Loss: 0.4282\t validation loss: 0.8826 | Accuracy: 0.8516\t validation accuracy: 0.625\n",
      "Epoch:   7 | Loss: 0.4566\t validation loss: 0.8737 | Accuracy: 0.8438\t validation accuracy: 0.6094\n",
      "Epoch:   7 | Loss: 0.4918\t validation loss: 0.9105 | Accuracy: 0.7969\t validation accuracy: 0.6094\n",
      "Epoch:   7 | Loss: 0.307\t validation loss: 0.8885 | Accuracy: 0.875\t validation accuracy: 0.6406\n",
      "Epoch:   7 | Loss: 0.4426\t validation loss: 0.885 | Accuracy: 0.8438\t validation accuracy: 0.6484\n",
      "Epoch:   7 | Loss: 0.4222\t validation loss: 0.9217 | Accuracy: 0.8125\t validation accuracy: 0.6016\n",
      "Epoch:   7 | Loss: 0.297\t validation loss: 0.9298 | Accuracy: 0.9141\t validation accuracy: 0.6094\n",
      "Epoch:   7 | Loss: 0.368\t validation loss: 0.8993 | Accuracy: 0.8359\t validation accuracy: 0.625\n",
      "Epoch:   7 | Loss: 0.4367\t validation loss: 0.8996 | Accuracy: 0.8359\t validation accuracy: 0.6172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   7 | Loss: 0.476\t validation loss: 0.8827 | Accuracy: 0.8281\t validation accuracy: 0.625\n",
      "Epoch:   7 | Loss: 0.4381\t validation loss: 0.8729 | Accuracy: 0.8438\t validation accuracy: 0.6406\n",
      "Epoch:   7 | Loss: 0.5151\t validation loss: 0.8559 | Accuracy: 0.8359\t validation accuracy: 0.6484\n",
      "Epoch:   7 | Loss: 0.3857\t validation loss: 0.8557 | Accuracy: 0.8359\t validation accuracy: 0.6641\n",
      "Epoch:   7 | Loss: 0.4732\t validation loss: 0.8597 | Accuracy: 0.8438\t validation accuracy: 0.6406\n",
      "Epoch:   7 | Loss: 0.3399\t validation loss: 0.859 | Accuracy: 0.8672\t validation accuracy: 0.6328\n",
      "Epoch:   7 | Loss: 0.4924\t validation loss: 0.8706 | Accuracy: 0.8203\t validation accuracy: 0.6328\n",
      "Epoch:   7 | Loss: 0.3416\t validation loss: 0.8789 | Accuracy: 0.8594\t validation accuracy: 0.6328\n",
      "Epoch:   7 | Loss: 0.2539\t validation loss: 0.852 | Accuracy: 0.8906\t validation accuracy: 0.6484\n",
      "Epoch:   7 | Loss: 0.4213\t validation loss: 0.8641 | Accuracy: 0.8438\t validation accuracy: 0.6484\n",
      "Epoch:   7 | Loss: 0.4089\t validation loss: 0.8648 | Accuracy: 0.8281\t validation accuracy: 0.6562\n",
      "Epoch:   7 | Loss: 0.3693\t validation loss: 0.8692 | Accuracy: 0.8359\t validation accuracy: 0.6328\n",
      "Epoch:   7 | Loss: 0.3363\t validation loss: 0.8768 | Accuracy: 0.8438\t validation accuracy: 0.6094\n",
      "Epoch:   7 | Loss: 0.4084\t validation loss: 0.8607 | Accuracy: 0.8125\t validation accuracy: 0.625\n",
      "Epoch:   7 | Loss: 0.3655\t validation loss: 0.8549 | Accuracy: 0.8594\t validation accuracy: 0.6172\n",
      "Epoch:   7 | Loss: 0.5061\t validation loss: 0.8433 | Accuracy: 0.7812\t validation accuracy: 0.6406\n",
      "Epoch:   7 | Loss: 0.2637\t validation loss: 0.8306 | Accuracy: 0.8984\t validation accuracy: 0.6328\n",
      "Epoch:   7 | Loss: 0.4516\t validation loss: 0.8371 | Accuracy: 0.8281\t validation accuracy: 0.6172\n",
      "Epoch:   7 | Loss: 0.5414\t validation loss: 0.8651 | Accuracy: 0.7812\t validation accuracy: 0.6406\n",
      "Epoch:   7 | Loss: 0.3299\t validation loss: 0.864 | Accuracy: 0.8984\t validation accuracy: 0.6406\n",
      "Epoch:   7 | Loss: 0.3752\t validation loss: 0.8566 | Accuracy: 0.8828\t validation accuracy: 0.6484\n",
      "Epoch:   7 | Loss: 0.3972\t validation loss: 0.8262 | Accuracy: 0.8438\t validation accuracy: 0.6484\n",
      "Epoch:   7 | Loss: 0.3246\t validation loss: 0.8721 | Accuracy: 0.8984\t validation accuracy: 0.6094\n",
      "Epoch:   7 | Loss: 0.4633\t validation loss: 0.8409 | Accuracy: 0.7969\t validation accuracy: 0.6406\n",
      "Epoch:   7 | Loss: 0.3835\t validation loss: 0.85 | Accuracy: 0.8906\t validation accuracy: 0.6406\n",
      "Epoch:   7 | Loss: 0.3474\t validation loss: 0.8529 | Accuracy: 0.8359\t validation accuracy: 0.6328\n",
      "Epoch:   7 | Loss: 0.6261\t validation loss: 0.8351 | Accuracy: 0.75\t validation accuracy: 0.6562\n",
      "Epoch:   7 | Loss: 0.4072\t validation loss: 0.8607 | Accuracy: 0.8359\t validation accuracy: 0.6484\n",
      "Epoch:   7 | Loss: 0.3794\t validation loss: 0.8516 | Accuracy: 0.8359\t validation accuracy: 0.6406\n",
      "Epoch:   8 | Loss: 0.3996\t validation loss: 0.853 | Accuracy: 0.8672\t validation accuracy: 0.625\n",
      "Epoch:   8 | Loss: 0.4433\t validation loss: 0.8638 | Accuracy: 0.8359\t validation accuracy: 0.625\n",
      "Epoch:   8 | Loss: 0.4054\t validation loss: 0.8577 | Accuracy: 0.8594\t validation accuracy: 0.6406\n",
      "Epoch:   8 | Loss: 0.4596\t validation loss: 0.8478 | Accuracy: 0.8594\t validation accuracy: 0.6406\n",
      "Epoch:   8 | Loss: 0.4516\t validation loss: 0.8834 | Accuracy: 0.8203\t validation accuracy: 0.6172\n",
      "Epoch:   8 | Loss: 0.2562\t validation loss: 0.8592 | Accuracy: 0.9062\t validation accuracy: 0.6406\n",
      "Epoch:   8 | Loss: 0.4103\t validation loss: 0.8415 | Accuracy: 0.8516\t validation accuracy: 0.6797\n",
      "Epoch:   8 | Loss: 0.3913\t validation loss: 0.8876 | Accuracy: 0.8359\t validation accuracy: 0.6328\n",
      "Epoch:   8 | Loss: 0.2671\t validation loss: 0.9024 | Accuracy: 0.9062\t validation accuracy: 0.6094\n",
      "Epoch:   8 | Loss: 0.3152\t validation loss: 0.8853 | Accuracy: 0.8516\t validation accuracy: 0.6328\n",
      "Epoch:   8 | Loss: 0.401\t validation loss: 0.8872 | Accuracy: 0.8594\t validation accuracy: 0.6094\n",
      "Epoch:   8 | Loss: 0.4464\t validation loss: 0.8748 | Accuracy: 0.8438\t validation accuracy: 0.6406\n",
      "Epoch:   8 | Loss: 0.4165\t validation loss: 0.8607 | Accuracy: 0.8594\t validation accuracy: 0.6484\n",
      "Epoch:   8 | Loss: 0.4871\t validation loss: 0.8485 | Accuracy: 0.8281\t validation accuracy: 0.6562\n",
      "Epoch:   8 | Loss: 0.3299\t validation loss: 0.8436 | Accuracy: 0.8828\t validation accuracy: 0.6719\n",
      "Epoch:   8 | Loss: 0.4454\t validation loss: 0.8437 | Accuracy: 0.8672\t validation accuracy: 0.6406\n",
      "Epoch:   8 | Loss: 0.3238\t validation loss: 0.8397 | Accuracy: 0.8828\t validation accuracy: 0.6406\n",
      "Epoch:   8 | Loss: 0.4487\t validation loss: 0.836 | Accuracy: 0.8359\t validation accuracy: 0.6719\n",
      "Epoch:   8 | Loss: 0.312\t validation loss: 0.852 | Accuracy: 0.8906\t validation accuracy: 0.6484\n",
      "Epoch:   8 | Loss: 0.2257\t validation loss: 0.8306 | Accuracy: 0.9297\t validation accuracy: 0.6406\n",
      "Epoch:   8 | Loss: 0.3838\t validation loss: 0.8451 | Accuracy: 0.8672\t validation accuracy: 0.6562\n",
      "Epoch:   8 | Loss: 0.3611\t validation loss: 0.8465 | Accuracy: 0.8594\t validation accuracy: 0.6484\n",
      "Epoch:   8 | Loss: 0.3398\t validation loss: 0.8415 | Accuracy: 0.8438\t validation accuracy: 0.625\n",
      "Epoch:   8 | Loss: 0.3171\t validation loss: 0.8535 | Accuracy: 0.8594\t validation accuracy: 0.6484\n",
      "Epoch:   8 | Loss: 0.3673\t validation loss: 0.8323 | Accuracy: 0.8438\t validation accuracy: 0.6562\n",
      "Epoch:   8 | Loss: 0.3477\t validation loss: 0.8247 | Accuracy: 0.8438\t validation accuracy: 0.6562\n",
      "Epoch:   8 | Loss: 0.4587\t validation loss: 0.8148 | Accuracy: 0.8047\t validation accuracy: 0.6328\n",
      "Epoch:   8 | Loss: 0.247\t validation loss: 0.8101 | Accuracy: 0.8984\t validation accuracy: 0.6562\n",
      "Epoch:   8 | Loss: 0.4201\t validation loss: 0.8083 | Accuracy: 0.8516\t validation accuracy: 0.6484\n",
      "Epoch:   8 | Loss: 0.4936\t validation loss: 0.8388 | Accuracy: 0.8047\t validation accuracy: 0.6641\n",
      "Epoch:   8 | Loss: 0.3005\t validation loss: 0.8408 | Accuracy: 0.8984\t validation accuracy: 0.6562\n",
      "Epoch:   8 | Loss: 0.3553\t validation loss: 0.8279 | Accuracy: 0.8828\t validation accuracy: 0.6719\n",
      "Epoch:   8 | Loss: 0.3713\t validation loss: 0.8029 | Accuracy: 0.8828\t validation accuracy: 0.6797\n",
      "Epoch:   8 | Loss: 0.3114\t validation loss: 0.8511 | Accuracy: 0.8984\t validation accuracy: 0.6484\n",
      "Epoch:   8 | Loss: 0.4337\t validation loss: 0.8141 | Accuracy: 0.8203\t validation accuracy: 0.6406\n",
      "Epoch:   8 | Loss: 0.3447\t validation loss: 0.819 | Accuracy: 0.8984\t validation accuracy: 0.6562\n",
      "Epoch:   8 | Loss: 0.3326\t validation loss: 0.8323 | Accuracy: 0.8438\t validation accuracy: 0.6406\n",
      "Epoch:   8 | Loss: 0.5563\t validation loss: 0.8135 | Accuracy: 0.7812\t validation accuracy: 0.6797\n",
      "Epoch:   8 | Loss: 0.3592\t validation loss: 0.8313 | Accuracy: 0.8594\t validation accuracy: 0.6562\n",
      "Epoch:   8 | Loss: 0.3408\t validation loss: 0.8303 | Accuracy: 0.8438\t validation accuracy: 0.6562\n",
      "Epoch:   9 | Loss: 0.3775\t validation loss: 0.8355 | Accuracy: 0.8672\t validation accuracy: 0.6562\n",
      "Epoch:   9 | Loss: 0.4234\t validation loss: 0.8416 | Accuracy: 0.8438\t validation accuracy: 0.6484\n",
      "Epoch:   9 | Loss: 0.3952\t validation loss: 0.8431 | Accuracy: 0.8516\t validation accuracy: 0.6562\n",
      "Epoch:   9 | Loss: 0.4083\t validation loss: 0.8258 | Accuracy: 0.8672\t validation accuracy: 0.6641\n",
      "Epoch:   9 | Loss: 0.4371\t validation loss: 0.8552 | Accuracy: 0.8359\t validation accuracy: 0.6406\n",
      "Epoch:   9 | Loss: 0.2336\t validation loss: 0.8415 | Accuracy: 0.9141\t validation accuracy: 0.6406\n",
      "Epoch:   9 | Loss: 0.383\t validation loss: 0.8166 | Accuracy: 0.8594\t validation accuracy: 0.6797\n",
      "Epoch:   9 | Loss: 0.3549\t validation loss: 0.8517 | Accuracy: 0.8516\t validation accuracy: 0.6484\n",
      "Epoch:   9 | Loss: 0.2425\t validation loss: 0.8703 | Accuracy: 0.9297\t validation accuracy: 0.6406\n",
      "Epoch:   9 | Loss: 0.2669\t validation loss: 0.8613 | Accuracy: 0.875\t validation accuracy: 0.6406\n",
      "Epoch:   9 | Loss: 0.3777\t validation loss: 0.8667 | Accuracy: 0.875\t validation accuracy: 0.6328\n",
      "Epoch:   9 | Loss: 0.4351\t validation loss: 0.867 | Accuracy: 0.8359\t validation accuracy: 0.6484\n",
      "Epoch:   9 | Loss: 0.3813\t validation loss: 0.8411 | Accuracy: 0.8828\t validation accuracy: 0.6562\n",
      "Epoch:   9 | Loss: 0.4474\t validation loss: 0.8352 | Accuracy: 0.8359\t validation accuracy: 0.6719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   9 | Loss: 0.305\t validation loss: 0.8257 | Accuracy: 0.8984\t validation accuracy: 0.6875\n",
      "Epoch:   9 | Loss: 0.4144\t validation loss: 0.8296 | Accuracy: 0.875\t validation accuracy: 0.6719\n",
      "Epoch:   9 | Loss: 0.3031\t validation loss: 0.8311 | Accuracy: 0.8828\t validation accuracy: 0.6328\n",
      "Epoch:   9 | Loss: 0.3965\t validation loss: 0.8411 | Accuracy: 0.8203\t validation accuracy: 0.6719\n",
      "Epoch:   9 | Loss: 0.3116\t validation loss: 0.8678 | Accuracy: 0.875\t validation accuracy: 0.6328\n",
      "Epoch:   9 | Loss: 0.2289\t validation loss: 0.8563 | Accuracy: 0.9219\t validation accuracy: 0.625\n",
      "Epoch:   9 | Loss: 0.3644\t validation loss: 0.8402 | Accuracy: 0.8594\t validation accuracy: 0.6562\n",
      "Epoch:   9 | Loss: 0.3149\t validation loss: 0.8525 | Accuracy: 0.8672\t validation accuracy: 0.6484\n",
      "Epoch:   9 | Loss: 0.3172\t validation loss: 0.849 | Accuracy: 0.8672\t validation accuracy: 0.6484\n",
      "Epoch:   9 | Loss: 0.3036\t validation loss: 0.8505 | Accuracy: 0.8594\t validation accuracy: 0.6406\n",
      "Epoch:   9 | Loss: 0.3476\t validation loss: 0.8475 | Accuracy: 0.8359\t validation accuracy: 0.6328\n",
      "Epoch:   9 | Loss: 0.3309\t validation loss: 0.835 | Accuracy: 0.875\t validation accuracy: 0.6406\n",
      "Epoch:   9 | Loss: 0.4373\t validation loss: 0.8167 | Accuracy: 0.8203\t validation accuracy: 0.6406\n",
      "Epoch:   9 | Loss: 0.2247\t validation loss: 0.8196 | Accuracy: 0.9375\t validation accuracy: 0.6562\n",
      "Epoch:   9 | Loss: 0.3825\t validation loss: 0.8093 | Accuracy: 0.8672\t validation accuracy: 0.6641\n",
      "Epoch:   9 | Loss: 0.4656\t validation loss: 0.8304 | Accuracy: 0.8438\t validation accuracy: 0.6562\n",
      "Epoch:   9 | Loss: 0.2982\t validation loss: 0.838 | Accuracy: 0.9062\t validation accuracy: 0.6641\n",
      "Epoch:   9 | Loss: 0.3385\t validation loss: 0.8315 | Accuracy: 0.8594\t validation accuracy: 0.6641\n",
      "Epoch:   9 | Loss: 0.3696\t validation loss: 0.8077 | Accuracy: 0.8672\t validation accuracy: 0.6797\n",
      "Epoch:   9 | Loss: 0.2831\t validation loss: 0.8326 | Accuracy: 0.8984\t validation accuracy: 0.6562\n",
      "Epoch:   9 | Loss: 0.3931\t validation loss: 0.8147 | Accuracy: 0.8516\t validation accuracy: 0.6562\n",
      "Epoch:   9 | Loss: 0.306\t validation loss: 0.8005 | Accuracy: 0.9062\t validation accuracy: 0.6797\n",
      "Epoch:   9 | Loss: 0.2802\t validation loss: 0.8193 | Accuracy: 0.8672\t validation accuracy: 0.6797\n",
      "Epoch:   9 | Loss: 0.4817\t validation loss: 0.8045 | Accuracy: 0.8203\t validation accuracy: 0.6875\n",
      "Epoch:   9 | Loss: 0.3205\t validation loss: 0.821 | Accuracy: 0.8672\t validation accuracy: 0.6641\n",
      "Epoch:   9 | Loss: 0.2688\t validation loss: 0.8309 | Accuracy: 0.9062\t validation accuracy: 0.6406\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    train(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
